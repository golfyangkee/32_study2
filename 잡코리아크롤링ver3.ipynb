{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "11a43187",
   "metadata": {},
   "outputs": [
    {
     "ename": "IncompleteRead",
     "evalue": "IncompleteRead(37960 bytes read, 212056 more expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m list_url \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://m.jobkorea.co.kr/Start/spec/view?C_Idx=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&Tab=3&VPage=1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m url \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(list_url)\n\u001b[1;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(url)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup( result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 2. 시청자 게시판의 날짜와 본문 내용을 가져옵니다.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\http\\client.py:482\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 482\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength)\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\http\\client.py:633\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m--> 633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(37960 bytes read, 212056 more expected)"
     ]
    }
   ],
   "source": [
    "# 1. 웹에서 html 문서를 가져와 beautifulsoup 으로 파싱\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request  # 웹상의 url 을 파이썬이 인식할 수 있도록 해주는 모듈\n",
    "import pandas as pd\n",
    "\n",
    "sub_total=pd.DataFrame()\n",
    "res_list=[]\n",
    "for i in range(1,1000):\n",
    "    list_url = ('https://m.jobkorea.co.kr/Start/spec/view?C_Idx='+ str(i) +'&Tab=3&VPage=1')\n",
    "    url = urllib.request.Request(list_url)\n",
    "\n",
    "    result = urllib.request.urlopen(url).read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup( result, \"html.parser\")\n",
    "    # 2. 시청자 게시판의 날짜와 본문 내용을 가져옵니다.\n",
    "    result1 = soup.find('h2', class_='co')  # 회사이름\n",
    "    result2 = soup.find_all('span', class_='score') # 점수들\n",
    "    result3 = soup.find_all('span', class_='cate') # 지원분야\n",
    "    result4 = soup.find_all('span', class_='txYear') # 시기\n",
    "    middle5 = soup.find('ul', class_='list')\n",
    "    if middle5 is not None:\n",
    "        result5 = middle5.find_all('span', class_='tx') # 대학, 계열, 전공\n",
    "\n",
    "    if result1 and result5 is not None:\n",
    "        # 3. 리스트에 담습니다.\n",
    "        params1 = []\n",
    "        params1.append(result1.get_text(\"  \", strip=True))\n",
    "        params1=[params1]   # 회사명\n",
    "        \n",
    "        params3= []\n",
    "        sub_li3=[]  # 지원분야\n",
    "        \n",
    "        params4= []\n",
    "        sub_li4=[]  # 시기 년만\n",
    "        se_li4=[]\n",
    "        \n",
    "        params5= []\n",
    "        sub_li5=[]  # 대학 계열 전공 분류\n",
    "        se_li5=[]\n",
    "\n",
    "\n",
    "        params2 = []\n",
    "        sub_li2=[] # 회사별 데이터\n",
    "\n",
    "        list3=[]  # 회사명 + 회사별 데이터\n",
    "        \n",
    "        \n",
    "        for j in result2:\n",
    "            params2.append(j.get_text(\"  \", strip=True)) # Score 1페이지에 있는 것들 나옴\n",
    "        for j in range(0,len(params2),10):\n",
    "            sub_li2.append(params2[j:j+10])\n",
    "        sub_li2.pop(-1) # 회사별 데이터\n",
    "        \n",
    "        for j in result3:\n",
    "            params3.append(j.get_text(\"  \", strip=True)) # Score 1페이지에 있는 것들 나옴\n",
    "        for j in range(len(params3)):\n",
    "            sub_li3.append([params3[j]]) # 지원분야\n",
    "        \n",
    "        for j in result4:\n",
    "            params4.append(j.get_text(\"  \", strip=True)) # Score 1페이지에 있는 것들 나옴\n",
    "        for i in params4:\n",
    "            se_li4.append(i.split(' '))\n",
    "        sub_li4 = [[item[0]] for item in se_li4] # 시기\n",
    "\n",
    "        for j in result5:\n",
    "            params5.append(j.get_text(\"  \", strip=True)) # Score 1페이지에 있는 것들 나옴\n",
    "        # 분류\n",
    "        for i in params5:\n",
    "            se_li5.append(i.split(' '))\n",
    "        \n",
    "        sub_li5 = [[item[0]] for item in se_li5] # 대학 \n",
    "        \n",
    "        sub_li6 = [[item[2]] for item in se_li5] # 계열\n",
    "        for sublist in sub_li6:\n",
    "            if '스펙지수' in sublist:\n",
    "                sublist[0] = '-'\n",
    "       \n",
    "        sub_li7 = [[item[3]] for item in se_li5]  # 전공\n",
    "\n",
    "        list3 = [item1 + item2 + item3 + item4 + item5 + item6 + item7 for item1, item2, item3, item4, item5, item6, item7 in zip(params1 * len(sub_li2),sub_li4,sub_li3,sub_li5,sub_li6,sub_li7, sub_li2)]\n",
    "        res_list.append(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2e76ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2d = [inner_list for outer_list in res_list for inner_list in outer_list]\n",
    "df=pd.DataFrame(data_2d,columns=['회사명','시기','지원분야','대학','계열','전공','학점','토익','토익스피킹','오픽','외국어','자격증','해외경험','인턴','수상내역','봉사'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "49350809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./잡코리아취업데이터종합추추추가.csv', encoding = 'utf-8-sig')\n",
    "# , encoding='EUC-KR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe9a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
